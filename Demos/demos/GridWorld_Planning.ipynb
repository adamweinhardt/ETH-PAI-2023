{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from gym import spaces \n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import Image\n",
    "import IPython\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from rllib.environment.mdps import EasyGridWorld\n",
    "from rllib.policy import TabularPolicy\n",
    "from rllib.value_function import TabularQFunction, TabularValueFunction\n",
    "from rllib.util.neural_networks.utilities import one_hot_encode\n",
    "from matplotlib import rcParams\n",
    "import copy \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "rcParams['font.size'] = 12\n",
    "\n",
    "rcParams['figure.figsize'] = (20, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {},
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_policy(q_function):\n",
    "    \"\"\"Extract a policy from the q_function.\"\"\"\n",
    "    policy = TabularPolicy(num_states=q_function.num_states, num_actions=q_function.num_actions)\n",
    "    for state in range(policy.num_states):\n",
    "        q_val = q_function(torch.tensor(state).long())\n",
    "        action = torch.argmax(q_val)\n",
    "        \n",
    "        policy.set_value(state, action)\n",
    "    \n",
    "    return policy \n",
    "\n",
    "def plan_policy(state, environment, value_function, gamma):\n",
    "    next_value = torch.zeros(environment.num_actions)  # value of taking the different actions.\n",
    "    for action in range(environment.num_actions):\n",
    "        value_estimate = 0\n",
    "\n",
    "        # In practice, we do not have access to environment.transitions, but only to samples of it!.\n",
    "        for transition in environment.transitions[(state, action)]:  \n",
    "            next_state = torch.tensor(transition[\"next_state\"]).long()\n",
    "            reward = torch.tensor(transition[\"reward\"]).double()\n",
    "            value_estimate += transition[\"probability\"] * (\n",
    "                reward + gamma * value_function(next_state)\n",
    "            )\n",
    "            \n",
    "        next_value[action] = value_estimate\n",
    "    policy = torch.where(next_value == torch.max(next_value))[0]\n",
    "    \n",
    "    return policy \n",
    "\n",
    "def integrate_q(q_function, policy):\n",
    "    value_function = TabularValueFunction(num_states = q_function.num_states)\n",
    "    for state in range(policy.num_states):\n",
    "        state = torch.tensor(state).long()\n",
    "        pi = Categorical(logits=policy(state))\n",
    "        value = 0\n",
    "        for action in range(policy.num_actions):\n",
    "            value += pi.probs[action] * q_function(state, torch.tensor(action).long())\n",
    "        \n",
    "        value_function.set_value(state, value)\n",
    "    \n",
    "    return value_function\n",
    "\n",
    "# Planning \n",
    "def init_value_function(num_states, terminal_states=None):\n",
    "    \"\"\"Initialize value function.\"\"\"\n",
    "    value_function = TabularValueFunction(num_states=num_states)\n",
    "    terminal_states = [] if terminal_states is None else terminal_states\n",
    "    for terminal_state in terminal_states:\n",
    "        value_function.set_value(terminal_state, 0)\n",
    "\n",
    "    return value_function\n",
    "\n",
    "# Plotters\n",
    "def policy2str(policy):\n",
    "    if len(policy) == 4:\n",
    "        return \"*\"\n",
    "    \n",
    "    left = u'\\u2190'\n",
    "    right = u'\\u2192'\n",
    "    up = u'\\u2191'\n",
    "    down = u'\\u2193'\n",
    "    policy_str = \"\"\n",
    "    if 0 in policy:\n",
    "        policy_str += down \n",
    "    if 1 in policy:\n",
    "        policy_str += up \n",
    "    if 2 in policy:\n",
    "        policy_str += right\n",
    "    if 3 in policy:\n",
    "        policy_str += left\n",
    "    return policy_str\n",
    "\n",
    "def plot_value_function(value_function, ax):\n",
    "    ax.imshow(value_function)\n",
    "    rows, cols = value_function.shape\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            ax.text(row, col, f\"{value_function[col, row]:.1f}\", ha=\"center\", va=\"center\", color=\"w\", fontsize=24)\n",
    "\n",
    "def plot_policy(policy, environment, ax):\n",
    "    ax.imshow(np.zeros((environment.height, environment.width)))\n",
    "    for row in range(environment.height):\n",
    "        for col in range(environment.width):\n",
    "            policy_ = policy(torch.tensor(row * environment.width + col))\n",
    "            ax.text(col, row, policy2str(policy_), ha=\"center\", va=\"center\", color=\"r\", fontsize=24)\n",
    "\n",
    "def plot_induced_policy(environment, value_function, gamma, ax):\n",
    "    ax.imshow(np.zeros((environment.height, environment.width)))\n",
    "    for row in range(environment.height):\n",
    "        for col in range(environment.width):\n",
    "            policy_ = plan_policy(row * environment.width + col, environment, value_function, gamma)\n",
    "            ax.text(col, row, policy2str(policy_), ha=\"center\", va=\"center\", color=\"r\", fontsize=24)\n",
    "            \n",
    "def plot_value_and_policy(value_function, policy):\n",
    "    fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(20, 8))\n",
    "    \n",
    "    plot_value_function(value_function, axes[0]) \n",
    "\n",
    "environment = EasyGridWorld()\n",
    "Image(\"images/grid_world.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid world Example \n",
    "#### Some explanation\n",
    "In this Markov Decision Processes the set of states are the (5x5) grid posions in which the agent can be located.\n",
    "The set of actions consists of: moving up, down, left, and right. \n",
    "\n",
    "The transition noise probability $\\delta$ corresponds to the probability with which the agent remains in the current state (i.e., does not move). With probabiliuty $1-\\delta$ the action is properly exectued an the agent moves to the adjacend grid cell indivated by the action, unless it hits a wall, in which case the agent remains in its current cell.\n",
    "\n",
    "This is a spare reward MDP. The agent will get a reward of +10 if it enters grid cell A and moves to A' regardless of the action. Similarly, the agent will get a +5 reward if it enters grid cell B and will be transferred to B'.\n",
    "If the agent bumps against the wall, it will get a reward of -1.\n",
    "\n",
    "For more details and derivation of MDPs you can check the [work](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf) of Sutton and Barto. Page 72, Example 3.8: Gridworld.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {},
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca660c6e4b4045168393d9cb82418166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.9, continuous_update=False, description='gamma', max=0.99, step=0.01…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def policy_evaluation_step(environment, policy, value_function, gamma, gauss_seidel=False):\n",
    "    max_error = 0\n",
    "    avg_error = 0\n",
    "    if gauss_seidel:\n",
    "        old_value_function = value_function\n",
    "    else:\n",
    "        \n",
    "        old_value_function = copy.deepcopy(value_function)\n",
    "    for state in range(environment.num_states):\n",
    "        if state in environment.terminal_states:\n",
    "            continue\n",
    "\n",
    "        value_estimate = torch.tensor(0.0)\n",
    "        state = torch.tensor(state).long()\n",
    "        policy_ = Categorical(logits=policy(state))\n",
    "\n",
    "        for action in np.where(policy_.probs.detach().numpy())[0]:\n",
    "            p_action = policy_.probs[action].item()\n",
    "\n",
    "            # In RL, we do not have access to environment.transitions, but only to samples of it!.\n",
    "            for transition in environment.transitions[(state.item(), action)]:\n",
    "                next_state = torch.tensor(transition[\"next_state\"]).long()\n",
    "                value_estimate += (\n",
    "                    p_action\n",
    "                    * transition[\"probability\"]\n",
    "                    * (transition[\"reward\"] + gamma * old_value_function(next_state).item())\n",
    "                )\n",
    "\n",
    "        value = value_function(state)\n",
    "        error = torch.abs(value_estimate - value).item()\n",
    "        max_error = max(max_error, error)\n",
    "        avg_error += error\n",
    "        value_function.set_value(state, value_estimate)\n",
    "    return max_error \n",
    "\n",
    "def iterative_policy_evaluation(environment, policy, gamma, eps=1e-6, max_iter=1000, gauss_seidel=False, value_function=None):\n",
    "    \"\"\"Implement Policy Evaluation algorithm (policy iteration without max).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    policy: TabularPolicy\n",
    "    gamma: float\n",
    "        discount factor.\n",
    "    eps: float \n",
    "        desired precision.\n",
    "    max_iter: int \n",
    "        Max number of iterations. \n",
    "    value_function: TabularValueFunction, optional. \n",
    "        Initial value function. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    value_function: TabularValueFunction\n",
    "        Value function associated to Policy.\n",
    "    num_iter: int\n",
    "        Number of iterations to reach `eps' accuracy. \n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction.\n",
    "    MIT press.\n",
    "    Chapter 4.1\n",
    "\n",
    "    \"\"\"\n",
    "    if value_function is None:\n",
    "        value_function = init_value_function(environment.num_states)\n",
    "    for num_iter in range(max_iter):\n",
    "        max_error = policy_evaluation_step(environment, policy, value_function, gamma, gauss_seidel=gauss_seidel)\n",
    "\n",
    "        if max_error < eps:\n",
    "            break\n",
    "    return value_function, num_iter\n",
    "\n",
    "def pe_interact(gamma, noise, gauss_seidel):\n",
    "    output = ipywidgets.Output()\n",
    "    environment = EasyGridWorld(noise=noise)\n",
    "    value_function = init_value_function(environment.num_states)\n",
    "    policy = TabularPolicy(num_states=environment.num_states, num_actions=environment.num_actions)\n",
    "\n",
    "    def plot_algorithm():\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            fig, ax = plt.subplots(ncols=2)\n",
    "            plot_policy(policy, environment, ax[1])\n",
    "            ax[1].set_title(\"Evaluated Policy\")\n",
    "\n",
    "            plot_value_function(value_function.table.reshape(5, 5).detach().numpy(), ax[0])\n",
    "            ax[0].set_title(\"Value Function\")\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "    def step():\n",
    "        max_error = policy_evaluation_step(environment, policy, value_function, gamma, gauss_seidel=gauss_seidel) \n",
    "        plot_algorithm()\n",
    "        print(f\"Max Bellman Error {max_error}\")\n",
    "        \n",
    "    plot_algorithm()\n",
    "    button = ipywidgets.Button(description=\"Step\")\n",
    "    button.on_click(lambda b: step())\n",
    "    display(button, output)\n",
    "    \n",
    "    \n",
    "interact(\n",
    "    pe_interact,\n",
    "    gamma=ipywidgets.FloatSlider(min=0, max=0.99, step=0.01, value=0.9, continuous_update=False),\n",
    "    noise=ipywidgets.FloatSlider(min=0, max=0.9, step=0.01, value=0, continuous_update=False),\n",
    "    gauss_seidel=False\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Guide:\n",
    "\n",
    "#### some explanation\n",
    "This demo above implement the policy evaluation on the gridworld. It means now given the policy we will calculate the long-term value using fixed point iteration. Note that current policy is randomly move to up, down, left or right.\n",
    "- gamma: Discount factor \n",
    "- noise: When noise > 0, then transitions happen with probability = 1-noise.\n",
    "    With probability noise the agent stays at the current state.\n",
    "- gauss_seidel: Method of successive displacement, more details could be checked [here](https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method).\n",
    "\n",
    "#### play around\n",
    "- Do the fixed point iteration yourself on some grid and compare the results\n",
    "- Play around with different noise and see the differences\n",
    "- Use the gauss_seidel and see the difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {}
   },
   "outputs": [],
   "source": [
    "def build_mrp_matrices(environment, policy):\n",
    "    mrp_kernel = np.zeros((environment.num_states, 1, environment.num_states))\n",
    "    mrp_reward = np.zeros((environment.num_states, 1))\n",
    "\n",
    "    for state in range(environment.num_states):\n",
    "        if state in environment.terminal_states:\n",
    "            mrp_kernel[state, 0, state] = 1\n",
    "            mrp_reward[state] = 0\n",
    "            continue\n",
    "\n",
    "        state = torch.tensor(state).long()\n",
    "        policy_ = Categorical(logits=policy(state))\n",
    "\n",
    "        for a, p_action in enumerate(policy_.probs):\n",
    "            for transition in environment.transitions[(state.item(), a)]:\n",
    "                with torch.no_grad():\n",
    "                    p_ns = transition[\"probability\"]\n",
    "                    mrp_reward[state, 0] += p_action * p_ns * transition[\"reward\"]\n",
    "                    mrp_kernel[state, 0, transition[\"next_state\"]] += p_action * p_ns\n",
    "    \n",
    "    return mrp_kernel, mrp_reward\n",
    "\n",
    "\n",
    "def average_policy_evaluation(environment, policy, value_function=None):\n",
    "    r\"\"\"Evaluate policy.\n",
    "\n",
    "    Finds stationary distribution (right eigenvector of 1 eigenvalue) and computes\n",
    "    ..math:: \\langle \\mu, r \\rangle.\n",
    "\n",
    "    \"\"\"\n",
    "    if value_function is None:\n",
    "        value_function = init_value_function(environment.num_states)\n",
    "        \n",
    "    kernel, reward = build_mrp_matrices(environment=environment, policy=policy)\n",
    "    eig_values, eig_vectors = np.linalg.eig(kernel[:, 0, :].T)\n",
    "    idx = np.where(np.isclose(eig_values, 1))[0]\n",
    "    stationary_distirbution = eig_vectors[:, idx] / eig_vectors[:, idx].sum()\n",
    "    average_reward = torch.tensor(np.real(reward.T @ stationary_distirbution)).float()[0, 0].item()\n",
    "    \n",
    "    new_reward = reward[:, 0] - average_reward\n",
    "    V = np.zeros(environment.num_states)\n",
    "    for i in range(1000):\n",
    "        V = new_reward + kernel[:, 0] @ V\n",
    "        V -= V.mean()\n",
    "\n",
    "    for state in range(value_function.num_states):\n",
    "        value_function.set_value(state, V[state])\n",
    "    \n",
    "    return value_function \n",
    "\n",
    "def linear_system_policy_evaluation(environment, policy, gamma, value_function=None):\n",
    "    \"\"\"Evaluate a policy in an MDP solving the system bellman of equations.\n",
    "\n",
    "    V = r + gamma * P * V\n",
    "    V = (I - gamma * P)^-1 r\n",
    "    \"\"\"\n",
    "    if gamma == 1:\n",
    "        return average_policy_evaluation(environment, policy)\n",
    "    \n",
    "    if value_function is None:\n",
    "        value_function = init_value_function(environment.num_states)\n",
    "\n",
    "    kernel, reward = build_mrp_matrices(environment=environment, policy=policy)\n",
    "\n",
    "    A = torch.eye(environment.num_states) - gamma * kernel[:, 0, :]\n",
    "    # torch.testing.assert_allclose(A.inverse() @ A, torch.eye(model.num_states))\n",
    "    vals = A.inverse() @ reward[:, 0]\n",
    "    for state in range(environment.num_states):\n",
    "        value_function.set_value(state, vals[state].item())\n",
    "\n",
    "    return value_function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {},
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c8d1083ea44e52a861709d079b2a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.9, continuous_update=False, description='gamma', max=0.99, step=0.01…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def value_iteration_step(environment, policy, value_function, gamma, gauss_seidel=False):\n",
    "    error = 0\n",
    "    if gauss_seidel:\n",
    "        old_value_function = value_function\n",
    "    else:\n",
    "        old_value_function = copy.deepcopy(value_function)\n",
    "    for state in range(environment.num_states):\n",
    "        value_ = torch.zeros(environment.num_actions)  # value of taking the different actions.\n",
    "        for action in range(environment.num_actions):\n",
    "            value_estimate = 0\n",
    "\n",
    "            # In practice, we do not have access to environment.transitions, but only to samples of it!.\n",
    "            for transition in environment.transitions[(state, action)]:  \n",
    "                next_state = torch.tensor(transition[\"next_state\"]).long()\n",
    "                reward = torch.tensor(transition[\"reward\"]).double()\n",
    "                value_estimate += transition[\"probability\"] * (\n",
    "                    reward + gamma * old_value_function(next_state)\n",
    "                )\n",
    "            value_[action] = value_estimate\n",
    "        state = torch.tensor(state).long()\n",
    "        value = value_function(state)\n",
    "        value_, action = torch.max(value_, 0)\n",
    "\n",
    "        error = max(error, torch.abs(value_ - value.item()))\n",
    "        value_function.set_value(state, value_)\n",
    "        policy.set_value(state, action)\n",
    "    return error \n",
    "\n",
    "def value_iteration(environment, gamma, eps=1e-6, max_iter=1000, gauss_seidel=False, value_function=None, policy=None):\n",
    "    \"\"\"Implement of Value Iteration algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gamma: float\n",
    "        discount factor.\n",
    "    eps: float \n",
    "        desired precision.\n",
    "    max_iter: int \n",
    "        Max number of iterations. \n",
    "    value_function: TabularValueFunction, optional. \n",
    "        Initial value function. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    value_function: TabularValueFunction\n",
    "        Optimal value function.\n",
    "    policy: Tabular Policy \n",
    "        Optimal policy. \n",
    "    num_iter: int\n",
    "        Number of iterations to reach `eps' accuracy. \n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction.\n",
    "    MIT press.\n",
    "    Chapter 4.4\n",
    "\n",
    "    \"\"\"\n",
    "    if value_function is None:\n",
    "        value_function = init_value_function(environment.num_states)\n",
    "    if policy is None:\n",
    "        policy = TabularPolicy(num_states=environment.num_states, num_actions=environment.num_actions)\n",
    "\n",
    "    for num_iter in range(max_iter):\n",
    "        error = value_iteration_step(environment, policy, value_function, gamma, gauss_seidel=gauss_seidel)\n",
    "\n",
    "        if error < eps:\n",
    "            break\n",
    "\n",
    "    return value_function, policy, num_iter \n",
    "\n",
    "\n",
    "\n",
    "def vi_interact(gamma, noise, gauss_seidel):\n",
    "    output = ipywidgets.Output()\n",
    "    environment = EasyGridWorld(noise=noise)\n",
    "    value_function = init_value_function(environment.num_states)\n",
    "    policy = TabularPolicy(num_states=environment.num_states, num_actions=environment.num_actions)\n",
    "\n",
    "    def plot_algorithm():\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            fig, ax = plt.subplots(ncols=2)\n",
    "            plot_induced_policy(environment, value_function, gamma, ax[1])\n",
    "            ax[1].set_title(\"Induced Policy\")\n",
    "\n",
    "            plot_value_function(value_function.table.reshape(5, 5).detach().numpy(), ax[0])\n",
    "            ax[0].set_title(\"Value Function\")\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "    def step(b):\n",
    "        max_error = value_iteration_step(environment, policy, value_function, gamma, gauss_seidel=gauss_seidel) \n",
    "        plot_algorithm()\n",
    "        print(f\"Max Bellman Error {max_error}\")\n",
    "        \n",
    "    plot_algorithm()\n",
    "    button = ipywidgets.Button(description=\"Step\")\n",
    "    button.on_click(step)\n",
    "    display(button, output)\n",
    "    \n",
    "    \n",
    "interact(\n",
    "    vi_interact,\n",
    "    gamma=ipywidgets.FloatSlider(min=0, max=0.99, step=0.01, value=0.9, continuous_update=False),\n",
    "    noise=ipywidgets.FloatSlider(min=0, max=0.9, step=0.01, value=0, continuous_update=False),\n",
    "    gauss_seidel=False\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Guide:\n",
    "\n",
    "#### some explanation\n",
    "This demo above implement the value iteration on the gridworld. It compute the Q value for all states action pairs and choose the geedy policy for the states until the convergence.\n",
    "- gamma:Discount factor \n",
    "- noise: When noise > 0, then transitions happen with probability = 1-noise.\n",
    "    With probability noise the agent stays at the current state.\n",
    "- gauss_seidel: Method of successive displacement, more details could be checked [here](https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method).\n",
    "\n",
    "#### play around\n",
    "- Do the value yourself on some grid and compare the results\n",
    "- Play around with different noise and see the differences\n",
    "- Use the gauss_seidel and see the difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {},
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe3cb2fd9f24097b2d83a5fcad80f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.9, continuous_update=False, description='gamma', max=0.99, step=0.01…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def policy_iteration_step(environment, policy, value_function, gamma):\n",
    "    value_function = linear_system_policy_evaluation(environment, policy, gamma)\n",
    "    policy_stable = True\n",
    "    for state in range(environment.num_states):\n",
    "\n",
    "        value_ = torch.zeros(environment.num_actions)\n",
    "        for action in range(environment.num_actions):\n",
    "            value_estimate = 0\n",
    "            for transition in environment.transitions[(state, action)]:\n",
    "                next_state = torch.tensor(transition[\"next_state\"]).long()\n",
    "                reward = torch.tensor(transition[\"reward\"]).double()\n",
    "                value_estimate += transition[\"probability\"] * (\n",
    "                    reward + gamma * value_function(next_state).item()\n",
    "                )\n",
    "\n",
    "            value_[action] = value_estimate\n",
    "\n",
    "        state = torch.tensor(state).long()\n",
    "        old_policy = policy(state)\n",
    "        old_action = torch.argmax(old_policy)\n",
    "\n",
    "        action = torch.argmax(value_)\n",
    "        policy.set_value(state, action)\n",
    "\n",
    "        policy_stable &= (action == old_action).all().item()\n",
    "    \n",
    "    return value_function, policy_stable \n",
    "\n",
    "\n",
    "def policy_iteration(environment, gamma, max_iter=10, value_function=None, policy=None):\n",
    "    \"\"\"Implement Policy Iteration algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gamma: float.\n",
    "        discount factor.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction.\n",
    "    MIT press.\n",
    "    Chapter 4.3\n",
    "\n",
    "    \"\"\"\n",
    "    if value_function is None:\n",
    "        value_function = init_value_function(environment.num_states)\n",
    "    if policy is None:\n",
    "        policy = TabularPolicy(num_states=environment.num_states, num_actions=environment.num_actions)\n",
    "\n",
    "    for num_iter in range(max_iter):\n",
    "        # Evaluate the policy. \n",
    "        value_function, policy_stable = policy_iteration_step(environment, policy, value_function, gamma)\n",
    "        \n",
    "        if policy_stable:\n",
    "            break\n",
    "    return value_function, policy, num_iter\n",
    "\n",
    "\n",
    "def pi_interact(gamma, noise):\n",
    "    output = ipywidgets.Output()\n",
    "    environment = EasyGridWorld(noise=noise)\n",
    "    value_function = init_value_function(environment.num_states)\n",
    "    policy = TabularPolicy(num_states=environment.num_states, num_actions=environment.num_actions)\n",
    "\n",
    "    def plot_algorithm(val_func):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            fig, ax = plt.subplots(ncols=2)\n",
    "            plot_induced_policy(environment, val_func, gamma, ax[1])\n",
    "            ax[1].set_title(\"Induced Policy\")\n",
    "\n",
    "            plot_value_function(val_func.table.reshape(5, 5).detach().numpy(), ax[0])\n",
    "            ax[0].set_title(\"Value Function\")\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "    def step(value_function):\n",
    "        value_function, policy_stable = policy_iteration_step(environment, policy, value_function, gamma)\n",
    "        plot_algorithm(value_function)\n",
    "        print(f\"Did the policy change? {'No' if policy_stable else 'Yes'}\")\n",
    "        \n",
    "    plot_algorithm(value_function)\n",
    "    button = ipywidgets.Button(description=\"Step\")\n",
    "    button.on_click(lambda b: step(value_function))\n",
    "    display(button, output)\n",
    "    \n",
    "    \n",
    "interact(\n",
    "    pi_interact,\n",
    "    gamma=ipywidgets.FloatSlider(min=0, max=0.99, step=0.01, value=0.9, continuous_update=False),\n",
    "    noise=ipywidgets.FloatSlider(min=0, max=0.9, step=0.01, value=0, continuous_update=False)\n",
    ");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Guide:\n",
    "\n",
    "#### some explanation\n",
    "This demo above implement the policy iteration on the gridworld. It starts with arbitrary policy and compute the value function iteratively and update the policy based on greedy algorithm \n",
    "- gamma:Discount factor \n",
    "- noise: When noise > 0, then transitions happen with probability = 1-noise.\n",
    "    With probability noise the agent stays at the current state.\n",
    "- gauss_seidel: Method of successive displacement, more details could be checked [here](https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method).\n",
    "\n",
    "#### play around\n",
    "- Do the policy iteration yourself on some grid and compare the results\n",
    "- Play around with different noise and see the differences\n",
    "- Compare with the value iteration above. Which one performs better in this demo?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {},
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a5e3ddae9d4decabc14854e712abcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='name', options=('Value Iteration', 'Policy Iteration', 'Linear Sys…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def algorithm_interact(name, gamma, noise, eps, gauss_seidel):\n",
    "    environment = EasyGridWorld(noise=noise)\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    plt.close()\n",
    "        \n",
    "    fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "    if name == \"Iterative Policy Evaluation\":\n",
    "        policy = TabularPolicy(num_states=environment.num_states, num_actions=environment.num_actions)\n",
    "        value_function, num_iter = iterative_policy_evaluation(environment, policy, gamma, max_iter=1000, eps=eps, gauss_seidel=gauss_seidel) \n",
    "        plot_policy(policy, environment, ax[1])\n",
    "        ax[1].set_title(\"Evaluated Policy\")\n",
    "\n",
    "    elif name == \"Linear System Policy Evaluation\":\n",
    "        policy = TabularPolicy(num_states=environment.num_states, num_actions=environment.num_actions)\n",
    "        value_function = linear_system_policy_evaluation(environment, policy, gamma)\n",
    "        num_iter = 1\n",
    "        plot_policy(policy, environment, ax[1])\n",
    "        ax[1].set_title(\"Evaluated Policy\")\n",
    "\n",
    "    elif name == \"Value Iteration\": \n",
    "        value_function, policy, num_iter = value_iteration(environment, gamma, eps=eps, gauss_seidel=gauss_seidel) \n",
    "        plot_induced_policy(environment, value_function, gamma, ax[1])\n",
    "        ax[1].set_title(\"Extracted Policy\")\n",
    "\n",
    "    elif name == \"Policy Iteration\": \n",
    "        value_function, policy, num_iter =  policy_iteration(environment, gamma)\n",
    "        plot_induced_policy(environment, value_function, gamma, ax[1])\n",
    "        ax[1].set_title(\"Extracted Policy\")\n",
    "\n",
    "    print(f\"Converged after {num_iter} {'iterations' if num_iter > 1 else 'iteration'}.\")\n",
    "\n",
    "    plot_value_function(value_function.table.reshape(5, 5).detach().numpy(), ax[0])\n",
    "    ax[0].set_title(\"Value Function\")\n",
    "    plt.show()\n",
    "    \n",
    "interact(\n",
    "    algorithm_interact,\n",
    "    name=[\"Value Iteration\", \"Policy Iteration\", \"Linear System Policy Evaluation\", \"Iterative Policy Evaluation\"],\n",
    "    gamma=ipywidgets.FloatSlider(min=0, max=0.99, step=0.01, value=0.9, continuous_update=False),\n",
    "    noise=ipywidgets.FloatSlider(min=0, max=0.9, step=0.01, value=0, continuous_update=False),\n",
    "    eps=ipywidgets.FloatLogSlider(min=-6, max=-1, step=0.01, value=1e-3, continuous_update=False),\n",
    "    gauss_seidel=False\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {}
   },
   "source": [
    "## Demo Guide:\n",
    "\n",
    "#### some explanation\n",
    "This demo provides 4 different method to help you understand the policy iteration and value iterations. Note that the first two method will converge to the optimal policy and correspondent value function, showing the iterations need for convergence. While the third and fourth methods are just policy evaluation method given the fixed policy.\n",
    "- gamma:Discount factor \n",
    "- noise: When noise > 0, then transitions happen with probability = 1-noise.\n",
    "    With probability noise the agent stays at the current state.\n",
    "- eps: desired precision for value iterations.\n",
    "- gauss_seidel: Method of successive displacement, more details could be checked [here](https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method).\n",
    "\n",
    "#### play around\n",
    "- Compre the iterations needed for convergence between policy iterations and value iterations. Which one is faster and why?\n",
    "- Change the desired precision and see the difference of iterations needed for convergence.\n",
    "- Compare with the iterate policy evaluation and linear system policy iterations. which one is faster in this demo? What happened if we have more states or more action options?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
