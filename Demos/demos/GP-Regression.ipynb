{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T18:27:39.885499Z",
     "start_time": "2021-10-10T18:27:39.881816Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- sampling\n",
    "from src.gp_sampling import *\n",
    "from src.gp_regression import *\n",
    "# --- style\n",
    "# If in your browser the figures are not nicely vizualized, please change the following\n",
    "rcParams['font.size'] = 12 \n",
    "rcParams['figure.figsize'] = (15,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sampling from a GP\n",
    "Demo explanation:\n",
    "* After specifying a kernel and its hyperparameters, we would like to sample functions from our GP. Two strategies to do this:\n",
    "* (1) *Cholesky decomposition*: $f = L\\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0, 1)$ and $K=LL^\\top$\n",
    "* (2) *Forward sampling*: $p(f_1, ..., f_N) = \\prod_{i=1}^N p(f_i|f_{1:i-1})$\n",
    "* You can choose to sample from the posterior (conditioned on observations) or directly from the prior\n",
    "* Lengthscale hyper-parameter is specific to RBF and Matern kernels, Sigma scales the linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac10534e488e45b2b6644bd0e3bea547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=4.0, description='lengthscale:', layout=Layout(width='500px'), max=8.0, min=1.0, step=0.5, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478ee38530b44b45a346ec8285ff7ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.5, description='sigma:', layout=Layout(width='500px'), max=1.0, min=0.001, step=0.05, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173410383559440e94e48d1918200a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=3, description='Number of points to condition on:', layout=Layout(width='500px'), max=9, min=3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdebc901209b4e44817bfe67d000987f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Kernel selection:', options=('RBF', 'Matern-1/2', 'Matern-3/2', 'Matern-5/2', 'Linear'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7ff3645ee44ce397f0cadd18e6e3a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Sampling type:', options=('Prior (Cholesky)', 'Posterior (Cholesky)', 'Posterior (Forwar…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4753908cc9144e394d383cf50fc2c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Resample', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78203c3d5dc349c3821da91d2c48985d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP regression with different kernel selection\n",
    "\n",
    "Demo explanation:\n",
    "* The true function is sinusoidal. \n",
    "* We obtain observations with iid. additive Gaussian noise.\n",
    "* We fit a GP with some specified kernel, or composition of kernels. RBF, quadratic, Matern have parameter *lengthscale*.\n",
    "* Another parameter is output scale: [explanation](https://docs.gpytorch.ai/en/stable/examples/00_Basic_Usage/Hyperparameters.html). One of raw parameters for learning\n",
    "* The likelihood noise variance can be specified as a hyperparameter.\n",
    "* Total uncertainty: Standard deviation of label y\n",
    "* Epistemic uncertainty: Come from the model confidence region (standard deviation of f)\n",
    "* Aleatoric uncertainty: The difference between above\n",
    "\n",
    "Play around:\n",
    "* Change the lengthscale to see how the complexity of the model influence the result\n",
    "* Try multiple kernel combinations and think about how to choose them based on data\n",
    "* Think about why the epistemic uncertainty is dominant in the data-lacking area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727c9d9d2b904b4398778e95d9b24f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=25, continuous_update=False, description='num_training', min=1), FloatSl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gp_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: Optimization of Hyper Parameters with type-II MLE.\n",
    "In this demo the model learn the best hyper parameters by optimizing the Marginal Likelihood.\n",
    "The second graph show the best model with learned hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T18:28:20.074768Z",
     "start_time": "2021-10-10T18:28:17.921756Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc8bef0a39d458db43d76fc25b9a119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=25, description='num_training', min=1), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mll_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Weather with GPs\n",
    "\n",
    "In this demo we use GPR to solve a real-world problem.\n",
    "\n",
    "Play around:\n",
    "* Think about what makes a good prediction\n",
    "* Try to find the best kernel combination for prediction both yearly and monthly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T18:28:52.190973Z",
     "start_time": "2021-10-10T18:28:51.278156Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2589d2592a5f42c49df0337118ffeec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='period', options=('yearly', 'monthly after 2010'), value='yearly')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gp_weather()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse GPs\n",
    "\n",
    "Demo guide:\n",
    "* Here we show different sparse GP / inducing-points methods\n",
    "* (1) [Deterministic Training Conditional (DTC)](http://proceedings.mlr.press/r4/seeger03a/seeger03a.pdf)\n",
    "* (2) [Subset of Regressors (SOR)](https://www.jmlr.org/papers/volume6/quinonero-candela05a/quinonero-candela05a.pdf)\n",
    "* (3) [Fully Independent Training Conditional (FITC)](https://papers.nips.cc/paper/2857-sparse-gaussian-processes-using-pseudo-inputs)\n",
    "\n",
    "Play around\n",
    "* Compare different methods for generating inducing points and their inference times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T18:29:30.178635Z",
     "start_time": "2021-10-10T18:29:29.875093Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b5aa57e7e446eba7017cf76352838b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=500, continuous_update=False, description='Number training points:', max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sparse_gp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Feature Approximation \n",
    "\n",
    "Demo guide:\n",
    "* Here we employ three random feature approximations to the RBF kernel\n",
    "* (1) [Random Fourier Features](https://people.eecs.berkeley.edu/~brecht/papers/07.rah.rec.nips.pdf)\n",
    "* (2) [Quadrature Fourier Features](https://papers.nips.cc/paper_files/paper/2018/hash/4e5046fc8d6a97d18a5f54beaed54dea-Abstract.html)\n",
    "* (3) [Orthogonal Random Features](https://arxiv.org/pdf/1610.09072.pdf)\n",
    "\n",
    "Play around:\n",
    "\n",
    "* Compare different kernel approximation methods\n",
    "* Try to change the number of random features and see how it will influence the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T18:29:38.872173Z",
     "start_time": "2021-10-10T18:29:38.849770Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c723f0d16e481f8e485a6987cff09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=500, continuous_update=False, description='Number training points:', max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_rff_gp_regression()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
